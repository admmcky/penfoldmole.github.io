title: Existential Hope in 2020 and Beyond with the FLI Team
original_url: '"https://zencastr.com/z/JGf517T4"'
date_published: '2019-12-28'
host:
  name: Lucas Perry
  affiliation: Future of Life Institute
guests:
- name: Jared Brown
  affiliation: Future of Life Institute
  title: Senior Advisor for Government Affairs
  bio: '"Jared helps inform and execute FLI''s strategic advocacy work on governmental
    policy."'
  expertise_areas:
  - Government Affairs
- name: Kirsten
  affiliation: Future of Life Institute
  title: Editorial Director
  bio: Kirsten runs the website, creates new content, manages other media, and experiments
    with communication strategies.
  expertise_areas:
  - Content Strategy
  - Effective Altruism
  - AI Risk
- name: Mayakita Tegmark
  affiliation: Future of Life Institute
  title: Co-founder and Treasurer
  bio: Mayakita focuses on outreach projects and is a postdoc in social psychology
    at Tufts University.
  expertise_areas:
  - Human-Robot Interaction
  - Social Psychology
- name: Tucker Davie
  affiliation: Future of Life Institute
  title: Core Team Member
  bio: '"Tucker works on FLI''s AI communication strategy and messaging."'
  expertise_areas:
  - AI Communication
  - Existential Risk Messaging
- name: Jessica Cousins Newman
  affiliation: Future of Life Institute
  title: AI Policy Specialist
  bio: Jessica works on AI policy, governance, and ethics, contributing to major AI
    governance forums.
  expertise_areas:
  - AI Policy
  - AI Governance
- name: Ian Rasconi
  affiliation: Future of Life Institute
  title: Podcast Producer and Editor
  bio: Ian edits and produces podcasts, focusing on audio quality and narrative coherence.
  expertise_areas:
  - Audio Production
  - Narrative Development
- name: Amelia Jaworski
  affiliation: Future of Life Institute
  title: Lethal Autonomous Weapons Advocate
  bio: Amelia is a physician and scientist focused on education and advocacy for autonomous
    weapons issues.
  expertise_areas:
  - Medical Ethics
  - Advocacy
- name: Anthony Aguirre
  affiliation: Future of Life Institute
  title: Professor of Physics
  bio: '"Anthony focuses on the policy-related aspects of AI and the Future of Life
    Institute''s efforts."'
  expertise_areas:
  - Physics
  - AI Policy
- name: Max Tegmark
  affiliation: Future of Life Institute
  title: Co-founder
  bio: '"Max is an MIT professor researching AI and focusing on technology''s impact
    on humanity."'
  expertise_areas:
  - Artificial Intelligence
  - Cosmology
synopsis: In this episode, members of the Future of Life Institute discuss their roles,
  projects, and insights regarding existential hope going into 2020 and beyond, reflecting
  on their achievements and future directions.
key_topics:
- Existential Risk
- AI Governance
- Lethal Autonomous Weapons
- Effective Altruism
- Policy Advocacy
tags:
- AI
- Ethics
- Technology
- Governance
key_points:
- The importance of proactive engagement in AI policy and ethical considerations.
- Recognition of collective effort in addressing existential risks through diverse
  projects and initiatives.
- Value of communication strategies in raising awareness about AI risks and effective
  altruism.
segments:
- title: Team Introductions
  summary: The FLI team introduces themselves and their roles, highlighting their
    contributions to various projects.
  key_quotes:
  - quote: '"I help inform and execute FLI''s strategic advocacy work on governmental
      policy."'
    speaker: Jared Brown
    context: Describing his role at FLI.
  - quote: '"I run the website and manage the content that''s being created."'
    speaker: Kirsten
    context: Kirsten outlining her responsibilities.
- title: Roles and Projects at FLI
  summary: Members share insights into their roles and ongoing projects, illustrating
    the interconnectivity of various initiatives.
  key_quotes:
  - quote: '"We''ve provided comments to the European Commission''s AI policy discussions."'
    speaker: Jessica Cousins Newman
    context: '"Discussing FLI''s participation in AI governance."'
- title: AI Policy and Ethics Discussion
  summary: The discussion centers on the challenges and importance of AI ethics and
    governance.
  key_quotes:
  - quote: We want to retain human control over decision-making.
    speaker: Amelia Jaworski
    context: On the importance of ethical considerations in technology.
- title: Motivations for Existential Risk Work
  summary: The team discusses what motivates their work in existential risk and the
    implications of emerging technologies.
  key_quotes:
  - quote: '"I''m motivated by both fear and hope."'
    speaker: Anthony Aguirre
    context: Expressing the dual motivations behind working on existential risks.
- title: Future Project Directions
  summary: The conversation looks forward to prospective projects and initiatives
    in 2020.
  key_quotes:
  - quote: I hope we can promote AI alignment and safety research.
    speaker: Max Tegmark
    context: '"Discussing FLI''s objectives for the upcoming years."'
websites_referenced:
- url: '"https://futureoflife.org"'
  name: Future of Life Institute
  context: The organization behind the podcast, focusing on ensuring that technology
    benefits humanity.
  access_date: '2023-10-15'
tools_mentioned:
- name: Metaculous
  url: '"https://metaculous.com"'
  description: A prediction platform aimed at improving decision-making through statistical
    forecasting.
  context: Utilized by FLI to improve predictive capabilities regarding future technology
    impacts.
research_papers:
- title: AI Policy Principles
  authors: []
  year: null
  url: ''
  key_findings: The increasing consensus on the need for ethical AI governance.
  context: ''
books_referenced:
- title: ''
  authors: []
  year: null
  isbn: ''
  context: ''
organizations:
  academic_institutions:
  - name: MIT
    location: Cambridge, MA
    context: '"Max Tegmark''s home institution for AI research."'
  companies:
  - name: ''
    industry: ''
    context: ''
  non_profits:
  - name: Future of Life Institute
    focus_area: Existential Risk Mitigation
    context: An advocacy group aimed at mitigating risks from emerging technologies.
  government_agencies:
  - name: ''
    country: ''
    context: ''
notable_people:
  academics:
  - name: Max Tegmark
    institution: MIT
    field: Artificial Intelligence
    context: Co-founder of FLI and researcher at MIT.
  industry_leaders:
  - name: ''
    company: ''
    role: ''
    context: ''
  policy_makers:
  - name: ''
    role: ''
    organization: ''
    context: ''
projects_mentioned:
- name: Partnership on AI
  organization: Various
  description: An organization to address ethical issues around artificial intelligence.
  status: Active
  url: ''
  context: ''
events:
  historical:
  - name: Beneficial AGI 2019 Conference
    date: '2019-01-01'
    significance: Gathering of AI researchers focusing on the ethical use of AI.
    context: '"FLI''s role in organizing discussions about the future of AI."'
  upcoming:
  - name: AI Policy Observatories
    date: null
    location: ''
    description: Establishment of platforms to monitor AI policy developments globally.
    url: ''
keywords:
- AI Ethics
- Existential Threats
- Future of Technology
- Global Cooperation
categories:
- Technology
- Ethics
- Policy Advocacy
intended_audience: Individuals interested in AI, ethics, and existential risk.
expertise_level: Intermediate
recommended_reading:
- title: '"Life 3.0: Being Human in the Age of Artificial Intelligence"'
  url: '"https://www.amazon.com/Life-3-0-Being-Human-Artificial/dp/0525558618"'
  type: book
  relevance: '"Gives context to FLI''s discussions on AI''s future impacts."'
action_items:
- Share the podcast with interested friends and followers.
- '"Engage with FLI''s upcoming initiatives on AI safety."'
controversial_topics:
- topic: Ethics of Autonomous Weapons
  different_viewpoints:
  - perspective: Support for development
    proponents: Some defense sectors and certain technologists
    key_arguments: Claim that they could reduce human casualties in warfare.
  - perspective: Opposition to development
    proponents: Numerous ethicists and humanitarian organizations
    key_arguments: Concerns over morality, accountability, and potential for misuse.
