title: '"Imagine A World: What if narrow AI fractured our shared reality?"'
original_url: '"https://zencastr.com/z/7FGg-8KT"'
date_published: 2023-10-10
host:
  name: Guillaume Reason
  affiliation: Future of Life Institute
guests:
- name: Michael Vassar
  affiliation: Machina Intelligence Research Institute, MetaMed Research
  title: Futurist, Activist, Entrepreneur
  bio: Michael Vassar is a futurist, activist, and entrepreneur with a background
    in biochemistry, economics, and business. He served as president of the Machine
    Intelligence Research Institute and co-founded MetaMed Research.
  expertise_areas:
  - Futurism
  - AI Ethics
  - Biochemistry
synopsis: '"In this episode of the Imagine A World podcast, host Guillaume Reason
  discusses the speculative world of ''Hall of Mirrors'' with creator Michael Vassar.
  The conversation explores themes of technology, society, and the impact of narrow
  AI on human existence."'
key_topics:
- Fiction and World-building
- Impact of AI on Society
- Isolation and Polarization
- Creative Collaboration
tags:
- AI
- Future of Life
- World-building
key_points:
- Narrow AI is more prevalent than AGI in the imagined future.
- Creative collaboration was vital in developing the Hall of Mirrors narrative.
- A deepening sense of isolation within media bubbles is a central theme.
- Societal norms and family dynamics evolve into a new currency.
segments:
- title: '"Introduction to ''Hall of Mirrors''"'
  summary: '"The podcast opens with a brief introduction to the contest by the Future
    of Life Institute and the concept of the world ''Hall of Mirrors''."'
  key_quotes:
  - quote: This world is a deeply unstable world where nothing is as it seems.
    speaker: Guillaume Reason
    context: Introduction to the podcast segment.
- title: '"Creative Dynamics in ''Hall of Mirrors''"'
  summary: Michael Vassar discusses the collaborative dynamics of creating the Hall
    of Mirrors narrative with his team.
  key_quotes:
  - quote: I had a lot of fun. It helped me to concretize some of my thinking.
    speaker: Michael Vassar
    context: Reflecting on his experience during the project collaboration.
- title: Impact of Media and AI on Society
  summary: The conversation delves into how AI technologies exacerbate societal isolation,
    leading to different realities within perceptual bubbles.
  key_quotes:
  - quote: The stories we tell ourselves about the world have a lot of inertia.
    speaker: Michael Vassar
    context: Discussing human experience within the constructed world.
- title: Control and Role of AGI and Narrow AI
  summary: Vassar explains how narrow AI operates under strict controls while an AGI
    named Siren remains cloistered.
  key_quotes:
  - quote: Allowing it to have more than the tiniest amount of impact on the world
      would be allowing the world to end almost immediately.
    speaker: Michael Vassar
    context: Describing the restrictions placed on AGI.
- title: Cultural Shifts and the Value of Connections
  summary: Discussion about how human relationships and family dynamics adapt in the
    world created by Vassar.
  key_quotes:
  - quote: Families become a currency or a kind of wealth that people pursue more
      than monetary assets.
    speaker: Michael Vassar
    context: Exploring the evolution of societal values in the imagined world.
websites_referenced:
- url: '"https://www.futureoflife.org"'
  name: Future of Life Institute
  context: Nonprofit advocating for safe and beneficial uses of transformative technologies.
  access_date: null
tools_mentioned:
- name: ''
  url: ''
  description: ''
  context: ''
research_papers:
- title: ''
  authors: []
  year: null
  url: ''
  key_findings: ''
  context: ''
books_referenced:
- title: ''
  authors: []
  year: null
  isbn: ''
  context: ''
organizations:
  academic_institutions:
  - name: University College London
    location: London, UK
    context: Institution where team member Mattia Franklin studies AI ethics and alignment.
  companies:
  - name: ''
    industry: ''
    context: ''
  non_profits:
  - name: Future of Life Institute
    focus_area: Reducing risks from transformative technologies.
    context: Founded to ensure the development and use of technologies to benefit
      life.
  government_agencies:
  - name: ''
    country: ''
    context: ''
notable_people:
  academics:
  - name: Mattia Franklin
    institution: University College London
    field: AI Ethics and Alignment
    context: Team member in the Hall of Mirrors project.
  industry_leaders:
  - name: ''
    company: ''
    role: ''
    context: ''
  policy_makers:
  - name: ''
    role: ''
    organization: ''
    context: ''
projects_mentioned:
- name: Hall of Mirrors
  organization: Future of Life Institute
  description: A speculative narrative created as part of a world-building contest.
  status: Contest Winner
  url: ''
  context: Explored as a podcast segment and highlights the future implications of
    AI.
events:
  historical:
  - name: COVID-19 Pandemic
    date: 2020
    significance: Led to significant governmental action and loss of public trust.
    context: Discussed in the lens of power and societal response.
  upcoming:
  - name: ''
    date: null
    location: ''
    description: ''
    url: ''
keywords:
- AI
- Society
- World-building
categories:
- Technology
- Futurism
intended_audience: Individuals interested in the future of society and technology.
expertise_level: Intermediate
recommended_reading:
- title: ''
  url: ''
  type: ''
  relevance: ''
action_items:
- Engage in discussions about the future scenarios presented in the episode.
- Reflect on the interplay between technology and societal dynamics.
controversial_topics:
- topic: Portrayal of AGI Development
  different_viewpoints:
  - perspective: Optimistic Slow Progress
    proponents: Michael Vassar
    key_arguments: Delayed AGI development is necessary for ensuring safety and beneficial
      outcomes.
  - perspective: Rapid Transformation Risks
    proponents: ''
    key_arguments: The risk of unchecked and rapid development of AGI poses existential
      threats.
