title: FLI 2016 - A Year In Review
original_url: '"https://zencastr.com/z/ITJq2vK5"'
date_published: '2016-12-30'
host:
  name: Anthony Geary
  affiliation: UC Santa Cruz
guests:
- name: Max Tegmark
  affiliation: Future of Life Institute
  title: President
  bio: Max Tegmark is a professor of physics and one of the co-founders of the Future
    of Life Institute.
  expertise_areas:
  - AI Safety
  - Physics
- name: David Stanley
  affiliation: Future of Life Institute
  title: Project Coordinator
  bio: David Stanley serves as a project coordinator and volunteer coordinator at
    FLI.
  expertise_areas:
  - Project Management
- name: Lucas Perry
  affiliation: Future of Life Institute
  title: Project Coordinator
  bio: Lucas Perry is the project coordinator with the Future of Life Institute.
  expertise_areas:
  - AI Safety
- name: Victoria Krakovna
  affiliation: Google DeepMind
  title: AI Safety Researcher
  bio: Victoria Krakovna is a co-founder of FLI and works at Google DeepMind focusing
    on AI safety.
  expertise_areas:
  - AI Safety
  - Machine Learning
- name: Richard Mala
  affiliation: Future of Life Institute
  title: Director of AI Projects
  bio: Richard Mala is the director of artificial intelligence projects at FLI.
  expertise_areas:
  - Artificial Intelligence
- name: Maya Akita Tegmark
  affiliation: Future of Life Institute
  title: Co-Founder
  bio: Maya Akita Tegmark is a co-founder of FLI, focusing on the psychological impacts
    of technology.
  expertise_areas:
  - Psychology
  - Technology Impact
- name: Arielle Kahn
  affiliation: Future of Life Institute
  title: Director of Media and Communications
  bio: Arielle Kahn serves as the Director of Media and Communications for FLI.
  expertise_areas:
  - Communication
  - Media Relations
synopsis: In this episode, key members of the Future of Life Institute reflect on
  the milestones achieved in 2016, discussing advancements in AI safety, nuclear risk
  reduction, and the importance of collaborative efforts to ensure beneficial futures
  for humanity.
key_topics:
- AI Safety
- Nuclear Weapons
- Technological Impact on Society
- International Cooperation
tags:
- Future of Life Institute
- AI
- Nuclear Safety
- Technology Ethics
key_points:
- FLI focused on beneficial AI and nuclear disarmament in 2016.
- Increased interest and funding in AI safety research.
- Successful divestment campaign against nuclear weapons producers.
segments:
- title: Introduction to FLI and Key Members
  summary: Members of the Future of Life Institute introduce themselves and their
    roles.
  key_quotes:
  - quote: We are focused on reducing existential risks and ensuring technology is
      developed safely.
    speaker: Max Tegmark
    context: Introduction on the mission of FLI.
- title: '"Achievements in 2016: AI Safety and Nuclear Efforts"'
  summary: Discussion on key achievements of FLI in 2016, including advancements in
    AI safety research and nuclear risk reduction.
  key_quotes:
  - quote: We need to win this race between the growing power of our technology and
      the wisdom with which we manage it.
    speaker: Max Tegmark
    context: Overview of technological advancements and their implications.
- title: '"Global Initiatives: Paris Climate Accords and UN Actions"'
  summary: Reactions to international agreements like the Paris Climate Accords and
    UN resolutions on nuclear weapons.
  key_quotes:
  - quote: The UN decided to start negotiations on the possibility of banning lethal
      autonomous weapons.
    speaker: Max Tegmark
    context: Mentioning the importance of international policy on technology.
- title: '"Focus on Beneficial AI: Ensuring Positive Impact"'
  summary: Discussion on the responsibility AI scientists have in ensuring technology
    benefits society.
  key_quotes:
  - quote: We think of AI scientists as the people who helped make the world better.
    speaker: Max Tegmark
    context: The expectation of AI professionals to guide ethical use of technology.
- title: Growth of AI Safety Research Field
  summary: Highlights the mainstreaming of AI safety research and interest from academia.
  key_quotes:
  - quote: The AI safety community has started to really take shape.
    speaker: Anthony Geary
    context: Reflections on the growth of AI safety as a research field.
- title: '"2017 Goals: AI and Nuclear Risk Reduction"'
  summary: Looking ahead to the goals for FLI in 2017, including AI safety, nuclear
    disarmament, and public engagement.
  key_quotes:
  - quote: We plan to focus primarily on artificial intelligence and on reducing the
      risk of accidental nuclear war.
    speaker: Max Tegmark
    context: Setting the agenda for future initiatives.
websites_referenced:
- url: '"https://futureoflife.org"'
  name: Future of Life Institute
  context: Main website for more information on their initiatives and research.
  access_date: '2023-10-01'
tools_mentioned: []
research_papers:
- title: Cooperative Inverse Reinforcement Learning
  authors:
  - Stuart Russell
  year: 2016
  url: ''
  key_findings: A framework for teaching AI to align its goals with human preferences.
  context: Published at NIPS, highlights the growing research in AI safety.
- title: Safely Interruptible Agents
  authors:
  - DeepMind
  - Future of Humanity Institute
  year: 2016
  url: ''
  key_findings: Formulates conditions under which AI systems can be safely interrupted.
  context: Brings focus on practical safety measures in AI development.
books_referenced: []
organizations:
  academic_institutions:
  - name: Future of Life Institute
    location: Global
    context: Non-profit organization focused on mitigating existential risks.
  companies:
  - name: Google DeepMind
    industry: Technology / AI
    context: Leading AI research lab focused on advanced AI technologies.
  non_profits:
  - name: Machine Intelligence Research Institute (MIRI)
    focus_area: AI Safety
    context: Organization focused on research related to the safe development of AI.
  government_agencies:
  - name: United Nations
    country: Global
    context: International body engaged in negotiations on nuclear weapons and AI
      ethics.
notable_people:
  academics:
  - name: Stuart Russell
    institution: University of California, Berkeley
    field: AI and Machine Learning
    context: Author of significant papers on AI safety and ethics.
  industry_leaders:
  - name: Demis Hassabis
    company: DeepMind
    role: CEO
    context: Prominent figure in AI development with a focus on safety.
  policy_makers: []
projects_mentioned: []
events:
  historical:
  - name: Paris Climate Accords
    date: '2016-04-22'
    significance: International agreement aimed at combating climate change.
    context: '"FLI''s acknowledgment of global efforts related to technology and climate."'
  - name: UN General Assembly Meeting (2016)
    date: '2016-11-15'
    significance: Start of negotiations on nuclear weapons reduction.
    context: '"Highlighting FLI''s focus on nuclear disarmament."'
  upcoming: []
keywords:
- AI Safety
- Nuclear Weapons
- Existential Risks
categories:
- Technology
- Public Policy
- Education
intended_audience: Researchers, policymakers, and the general public interested in
  AI and existential risks.
expertise_level: Intermediate
recommended_reading:
- title: '"Life 3.0: Being Human in the Age of Artificial Intelligence"'
  url: ''
  type: book
  relevance: Explores the impact of AI on society and is recommended for understanding
    future challenges.
action_items:
- Increase international collaboration on AI safety and nuclear disarmament.
- Promote public engagement in discussions about AI and its impact on society.
controversial_topics:
- topic: Ethics in AI Development
  different_viewpoints:
  - perspective: AI should prioritize safety and ethical guidelines.
    proponents: Max Tegmark, Victoria Krakovna
    key_arguments: Emphasizing responsibility in AI design to prevent misuses.
  - perspective: Rapid development without strict regulations could lead to risks.
    proponents: Anthony Geary, Richard Mala
    key_arguments: Concern over potential unforeseen consequences of advanced AI.
