title: Six Experts Explain the Killer Robots Debate
original_url: '"https://zencastr.com/z/Lex-z7Rd"'
date_published: 2018-07-31
host:
  name: Arielle Kahn
  affiliation: Future of Life Institute
guests:
- name: Paul Schare
  affiliation: Center for New American Security
  title: Senior Fellow and Director
  bio: Defense expert with experience in military operations and policy issues for
    emerging weapons technologies.
  expertise_areas:
  - Autonomous Weapons
  - Military Technology
- name: Toby Walsh
  affiliation: University of New South Wales
  title: Scientific Professor of Artificial Intelligence
  bio: AI researcher and activist concerned about the implications of AI in warfare.
  expertise_areas:
  - Artificial Intelligence
  - Ethics of AI
- name: Richard Moyes
  affiliation: Article 36
  title: Managing Director
  bio: Co-founder of Article 36 focusing on weapons policy and law.
  expertise_areas:
  - Weapons Policy
  - Human Rights Law
- name: Mary Wareham
  affiliation: Human Rights Watch
  title: Advocacy Director of Arms Division
  bio: Global coordinator of the campaign to stop killer robots.
  expertise_areas:
  - Human Rights
  - Armed Conflict
- name: Bonnie Dougherty
  affiliation: Human Rights Watch
  title: Senior Researcher
  bio: '"Director of Armed Conflict and Civilian Protection at Harvard Law School''s
    International Human Rights Clinic."'
  expertise_areas:
  - Human Rights Law
  - Armed Conflict
- name: Peter Asaro
  affiliation: International Committee for Robot Arms Control
  title: Co-Founder and Vice Chair
  bio: Philosopher and researcher focused on the ethical implications of robotics
    and AI.
  expertise_areas:
  - Military Ethics
  - Philosophy of AI
synopsis: This episode delves into the complex debate surrounding lethal autonomous
  weapons with leading experts discussing their definitions, implications, and the
  ethical issues involved.
key_topics:
- Lethal Autonomous Weapons
- International Humanitarian Law
- Ethics of AI in Warfare
- Human Control in Decision-Making
tags:
- Autonomous Weapons
- AI Ethics
- Military Technology
key_points:
- A broad coalition of over 220 AI organizations signed a pledge against lethal autonomous
  weapons.
- The debate around autonomous weapons highlights significant ethical, legal, and
  technological concerns.
- There is a call for international regulations to ensure meaningful human control
  in warfare.
segments:
- title: Introduction to the Pledge Against Lethal Autonomous Weapons
  summary: Arielle Kahn introduces the pledge and the initial signatories, emphasizing
    international norms against the development and use of lethal autonomous weapons.
  key_quotes:
  - quote: Over 220 AI-related organizations and over 2,800 individuals have signed
      the pledge.
    speaker: Arielle Kahn
    context: Introduction to the scope and impact of the pledge.
- title: Complexities of Autonomous Weapons
  summary: '"Experts discuss the different interpretations of ''autonomous weapons''
    and their implications for warfare."'
  key_quotes:
  - quote: '"The last thing they''re worried about is malicious AI."'
    speaker: Paul Schare
    context: Expressing the concerns related to lethal autonomous weapons versus rogue
      AI.
- title: Human Control in Weapon Systems
  summary: '"The need for ''meaningful human control'' over autonomous weapons is
    emphasized in international discussions."'
  key_quotes:
  - quote: '"Simply having a human in the loop doesn''t involve meaningful engagement."'
    speaker: Richard Moyes
    context: Discussing the definition and implications of human control in warfare.
- title: UN Efforts to Ban Lethal Autonomous Weapons
  summary: Mary Wareham and Bonnie Dougherty discuss the humanitarian impact and ongoing
    UN processes aimed at banning these weapons.
  key_quotes:
  - quote: '"Once they come into existence, it''s too late."'
    speaker: Bonnie Dougherty
    context: Emphasizing the urgency of preemptively banning lethal autonomous weapons.
websites_referenced:
- url: '"https://autonomousweapons.org"'
  name: Campaign to Stop Killer Robots
  context: Website dedicated to the advocacy against lethal autonomous weapons.
  access_date: null
- url: '"https://www.hrw.org"'
  name: Human Rights Watch
  context: Organization involved in monitoring human rights and advocating against
    autonomous weapons.
  access_date: null
tools_mentioned:
- name: Future of Life Institute
  url: '"https://futureoflife.org"'
  description: Organization focusing on mitigating risks from advanced technologies
    like AI.
  context: Hosting discussions and resources on autonomous weapons.
research_papers:
- title: The Ethical Responsibility of Military AI
  authors:
  - Peter Asaro
  - Paul Schare
  year: null
  url: ''
  key_findings: Explores the implications of using AI for lethal decision-making.
  context: Discusses the ethical frameworks necessary for the use of AI in military
    contexts.
books_referenced:
- title: '"Army of None: Autonomous Weapons and the Future of War"'
  authors:
  - Paul Schare
  year: null
  isbn: ''
  context: Highlights the history and future challenges of autonomous weapons.
organizations:
  academic_institutions:
  - name: University of New South Wales
    location: Sydney, Australia
    context: Conducts research on artificial intelligence and its implications.
  companies:
  - name: Google DeepMind
    industry: Artificial Intelligence
    context: Signatory of the pledge against lethal autonomous weapons.
  non_profits:
  - name: Human Rights Watch
    focus_area: Civil Rights
    context: Advocacy group involved in the campaign to stop killer robots.
  government_agencies:
  - name: United Nations
    country: International
    context: Engaged in discussions and negotiations around banning autonomous weapons.
notable_people:
  academics:
  - name: Stuart Russell
    institution: University of California, Berkeley
    field: Artificial Intelligence
    context: Prominent researcher and advocate for AI ethics.
  industry_leaders:
  - name: Elon Musk
    company: Tesla, Inc.
    role: CEO
    context: Signatory of the pledge against lethal autonomous weapons.
  policy_makers:
  - name: Alex Sobol
    role: Member of Parliament
    organization: United Kingdom
    context: Involved in discussions on the implications of autonomous weaponry.
projects_mentioned:
- name: Project Maven
  organization: Google
  description: Pentagon project aiming to use AI for drone footage analysis.
  status: Ongoing, but under scrutiny.
  url: '"https://cloud.google.com/maven"'
  context: Project that sparked discussions about ethical AI applications in military.
events:
  historical:
  - name: Campaign to Stop Killer Robots Launched
    date: null
    significance: Formation of a coalition against lethal autonomous weapons.
    context: Started with over 26 organizations.
  upcoming:
  - name: UN Meeting on Autonomous Weapons
    date: null
    location: Geneva, Switzerland
    description: Future negotiations on arms control regarding lethal autonomous weapons.
    url: ''
keywords:
- Killer Robots
- AI Ethics
- Military Technology
categories:
- Technology
- Ethics
- Global Policy
intended_audience: Researchers, policy makers, and the general public interested in
  AI ethics.
expertise_level: Intermediate
recommended_reading:
- title: '"Lethal Autonomous Weapons: The Legal and Ethical Debate"'
  url: ''
  type: Research Paper
  relevance: Analyzes international legal frameworks concerning autonomous weapons.
action_items:
- Sign the pledge against the development of lethal autonomous weapons.
- Stay informed on the discussions at the United Nations regarding weapons regulation.
controversial_topics:
- topic: Lethal Autonomous Weapons Regulation
  different_viewpoints:
  - perspective: Support for a ban due to ethical concerns.
    proponents: Human Rights Watch, Future of Life Institute.
    key_arguments: Autonomous weapons raise serious ethical and humanitarian issues.
  - perspective: Advocates for continued development citing military advantages.
    proponents: Some military leaders and contract companies.
    key_arguments: Argue the need for technological superiority and national security.
